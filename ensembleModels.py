# -*- coding: utf-8 -*-
"""
This model is based on features generated from analysis and models which are implemented prior to this model.
Please use the other scripts to genearte the feature file prior to running this script or use the features file attached to this repository.
The features in this file are combined from different files into one file.
"""
#Importing required libraries

import pandas as pd 
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import os
import math

from scipy import interpolate
%matplotlib qt

from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_predict

os.getcwd()
os.chdir('')

    
    
df=pd.read_csv('features.csv')
#features file is generated by using userweights, time weights and probability estimates for each user of each question
df['userweights'].isnull()
df=df[df.userweights.isnull()==False]    
len(df)    
df.columns
X=df[['userweights','w','new_value']] 
y=df['settled_value']
  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

rf = RandomForestRegressor(n_estimators = 10)
logreg = LogisticRegression()
rf.fit(X_train, y_train) #training the algorithm

y_pred = rf.predict(X_test)
y_predtr = rf.predict(X_train)

#Simple Average calculation using predictions made by random forest model
df1=pd.DataFrame(X_train)
df2=pd.DataFrame(X_test)
newdf=pd.concat([df1,df2])

y1=np.hstack((y_predtr,y_test))
newdf.columns
newdf['y']=y1
newdf=newdf.sort_index()
len(newdf)
newdf['qid']=df['question_id']
newdf['settled_value']=df['settled_value']
newdf2=newdf.groupby(['qid']).mean()
newdf2=newdf2.reset_index()
newdf2['AE']=abs(newdf2['settled_value']-newdf2['y'])
#Mean Absolute Error for all the questions
round(newdf2['AE'].mean(),2)


#Variable Importance
fea=df.drop(['settled_value','user_id','question_id'],axis=1)
feature_list=(fea.columns)
importances = list(rf.feature_importances_)
feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]

feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)

[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];